{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41fd1f78-000f-443c-8a35-43fe19ba4841",
   "metadata": {},
   "source": [
    "# 第４章: [形態素解析](https://nlp100.github.io/ja/ch04.html)\n",
    "\n",
    "[脇田の回答例](https://colab.research.google.com/drive/1NIrvOIfSCH_v9drBXA9LTCoFchbU3xHq?usp=sharing)\n",
    "\n",
    "## 参考資料\n",
    "\n",
    "- [An Introduction to Natural Language in Python using spaCy](https://colab.research.google.com/github/DerwenAI/spaCy_tuTorial/blob/master/spaCy_tuTorial.ipynb#scrollTo=v95pjRb1H87Z)\n",
    "    これは Google Colab とは独立した SpaCy の解説のようだ\n",
    "\n",
    "- [How to get started with SpaCy and its module in Google Colab?](https://stackoverflow.com/questions/59484501/how-to-get-started-with-spacy-library-and-its-module-in-google-colab): (answered at S/O on 2019-12-28)\n",
    "\n",
    "    SpaCy のアップグレード、モデルのダウンロード、などなどが必要。\n",
    "    \n",
    "- [How do I import the saved ~module~ model in Google Colab](https://stackoverflow.com/questions/67646437/how-do-i-import-the-saved-module-in-google-colab)\n",
    "\n",
    "    この質問は Google Drive に保存したモデルを使って spaCy を利用する方法について。`drive.mount` してから、`nlp.to_disk(\"RCM.model\")` と `spacy.load(\"RCM.model\")` を使えばよいようだ。共有ドライブでこれらの機能が動けば嬉しい。\n",
    "\n",
    "- [GoogleColabで日本語NLPライブラリGiNZAがloadできない](https://www.mojirca.com/2019/10/colab-load-ginza.html)\n",
    "\n",
    "    日本語の場合は GiNZA を使う。\n",
    "\n",
    "- [Colabで日本語対応したspaCyを動かしてみる](https://qiita.com/matsunori39/items/b7905bb3c838b5862c32): (Qiita on 2022-01-27)\n",
    "\n",
    "    GiNZA についてはこちらの方がまとまっているかも"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98431631-31e4-4845-9189-fe6019813b0f",
   "metadata": {},
   "source": [
    "# Google Drive へのアクセス\n",
    "\n",
    "第３章で経験したように Google Colaboratory はファイルの読み書きはできる。しかし、Colaboratory は一時的な仮想機械で動いているため、Colaboratory の仮想記憶を停止した時点でファイル群は消えてなくなる。これで恒久的に保存したいファイルへのアクセスができなくて困ることがある。\n",
    "\n",
    "Colaboratory に Google Drive へのアクセス権限を付与することで Google Drive 上のファイルを読み書きできるようになる。このような利用例に繰り返し利用するデータセットがある。データセットを Google Drive に保存しておき、それに Colaboratory からアクセスすれば Colaboratory を起動するごとにデータセットをダウンロードしなくてすむ。\n",
    "\n",
    "Google Drive から共有された巨大なデータセットについては、それを自分の Drive に保存しないでも直接読み込むことができるかもしれない。もし、それが可能なら自分の Google Drive の容量を圧迫しないですみそうだ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326fd752-7a2b-4a90-ac74-f1442c9669ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive は Google Colaboratory の仮想機械にマウントしてアクセス可能にする。\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/drive', force_remount=True)\n",
    "\n",
    "with open('/drive/MyDrive/hello.txt', 'w') as w:\n",
    "    w.write('Hello Google Colaboratory!\\n')\n",
    "\n",
    "# ちゃんと書き込まれているか確認する\n",
    "with open('/drive/MyDrive/hello.txt') as r:\n",
    "    print(r.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a210f0c3-cecc-49c4-9a40-d72721d247cb",
   "metadata": {},
   "source": [
    "# spaCy のアップグレードと実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6393f1f-2fde-4c05-bcca-db571be147c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/Users/wakita/.venvs/book/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Name: spacy\n",
      "Version: 3.2.3\n",
      "Summary: Industrial-strength Natural Language Processing (NLP) in Python\n",
      "Home-page: https://spacy.io\n",
      "Author: Explosion\n",
      "Author-email: contact@explosion.ai\n",
      "License: MIT\n",
      "Location: /Users/wakita/.venvs/book/lib/python3.9/site-packages\n",
      "Requires: blis, catalogue, cymem, jinja2, langcodes, murmurhash, numpy, packaging, pathy, preshed, pydantic, requests, setuptools, spacy-legacy, spacy-loggers, srsly, thinc, tqdm, typer, wasabi\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# !pip show spacy   # Colaboratory 上のバージョンは v2.2.4 (2022-03-12)。最新版は v3.2\n",
    "!pip install --upgrade spacy --quiet\n",
    "!pip show spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375703b1-e4f3-4730-8234-ad96e7fb24e9",
   "metadata": {},
   "source": [
    "日本語版の spaCy の利用には sudachi (`sudachipy` と `sudachidict_core`) が必要になる。これらを一括インストールするパッケージが `spacy[ja]` らしい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac0d56c3-fadd-498c-898b-ac30bf285f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: SudachiPy\n",
      "Version: 0.6.3\n",
      "Summary: Python version of Sudachi, the Japanese Morphological Analyzer\n",
      "Home-page: https://github.com/WorksApplications/sudachi.rs/tree/develop/python\n",
      "Author: Works Applications\n",
      "Author-email: sudachi@worksap.co.jp\n",
      "License: Apache-2.0\n",
      "Location: /Users/wakita/.venvs/book/lib/python3.9/site-packages\n",
      "Requires: \n",
      "Required-by: SudachiDict-core\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip --quiet\n",
    "!pip install 'spacy[ja]' --quiet\n",
    "!pip show 'sudachipy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "468c589c-36ea-45bd-b39c-430a760c64cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "国境の長いトンネルを抜けると雪国であった。"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.blank(\"ja\")\n",
    "\n",
    "doc = nlp('国境の長いトンネルを抜けると雪国であった。')\n",
    "\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bdf480-2020-4444-af68-d6fe57ba95b2",
   "metadata": {},
   "source": [
    "spaCy の `doc` オブジェクトは一見すると文字列に見えるけれども、実はトークン列を表現している。以下ではトークンが提供する属性を列挙している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17ba6a2b-9242-4efb-98b9-ccda0b5f3176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "`ancestors`, `check_flag`, `children`, `cluster`, `conjuncts`, `dep`, `dep_`, `doc`, `ent_id`, `ent_id_`, `ent_iob`, `ent_iob_`, `ent_kb_id`, `ent_kb_id_`, `ent_type`, `ent_type_`, `get_extension`, `has_dep`, `has_extension`, `has_head`, `has_morph`, `has_vector`, `head`, `i`, `idx`, `iob_strings`, `is_alpha`, `is_ancestor`, `is_ascii`, `is_bracket`, `is_currency`, `is_digit`, `is_left_punct`, `is_lower`, `is_oov`, `is_punct`, `is_quote`, `is_right_punct`, `is_sent_end`, `is_sent_start`, `is_space`, `is_stop`, `is_title`, `is_upper`, `lang`, `lang_`, `left_edge`, `lefts`, `lemma`, `lemma_`, `lex`, `lex_id`, `like_email`, `like_num`, `like_url`, `lower`, `lower_`, `morph`, `n_lefts`, `n_rights`, `nbor`, `norm`, `norm_`, `orth`, `orth_`, `pos`, `pos_`, `prefix`, `prefix_`, `prob`, `rank`, `remove_extension`, `right_edge`, `rights`, `sent`, `sent_start`, `sentiment`, `set_extension`, `set_morph`, `shape`, `shape_`, `similarity`, `subtree`, `suffix`, `suffix_`, `tag`, `tag_`, `tensor`, `text`, `text_with_ws`, `vector`, `vector_norm`, `vocab`, `whitespace_`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML, Markdown\n",
    "\n",
    "Markdown(', '.join([f'`{attr}`' for attr in dir(doc[0]) if not attr.startswith('_')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "176b61e3-ac4c-4e03-bef6-9f6892216a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('国境', '国境', 'NOUN', 'noun')\n",
      "('の', 'の', 'ADP', 'adposition')\n",
      "('長い', '長い', 'ADJ', 'adjective')\n",
      "('トンネル', 'トンネル', 'NOUN', 'noun')\n",
      "('を', 'を', 'ADP', 'adposition')\n",
      "('抜ける', '抜ける', 'VERB', 'verb')\n",
      "('と', 'と', 'SCONJ', 'subordinating conjunction')\n",
      "('雪国', '雪国', 'NOUN', 'noun')\n",
      "('で', 'だ', 'AUX', 'auxiliary')\n",
      "('あっ', 'ある', 'AUX', 'auxiliary')\n",
      "('た', 'た', 'AUX', 'auxiliary')\n",
      "('。', '。', 'PUNCT', 'punctuation')\n"
     ]
    }
   ],
   "source": [
    "for t in doc:\n",
    "    print((t.text, t.lemma_, t.pos_, spacy.explain(t.pos_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84062053-29bc-4b6a-a7bc-df416e675fd1",
   "metadata": {},
   "source": [
    "ところで、前述のトークンの属性を眺めると lemma と lemma_ のようによく似た属性があることに気付くだろう。spaCy は記憶領域を圧縮するためにカテゴリー値を Hash 値で表現している。_ を含まない属性名はそのような Hash 値を表し、それに対応した _ で終わる属性は元の値を表す。\n",
    "たとえば、「雪国」のlemma について調べてみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "261a2563-ed5e-4a93-a6a6-a04e53ceba66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7845350659413489886, '雪国', 92, 'NOUN')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for t in doc:\n",
    "    if t.text == '雪国':\n",
    "        雪国 = t\n",
    "\n",
    "(雪国.lemma, 雪国.lemma_, 雪国.pos, 雪国.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6893ff97-fa36-4fe9-a015-38cf29d9c0a0",
   "metadata": {},
   "source": [
    "このように `_` で終わる属性名を持つ属性が Hash 表現されたものと考えられるので、それらを列挙すると spaCy のだいたいの機能がわかると思う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f15e1c68-28f6-4e70-b54a-01757241abd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "dep, ent_id, ent_iob, ent_kb_id, ent_type, lang, lemma, lower, norm, orth, pos, prefix, shape, suffix, tag"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_attrs = dir(雪国)\n",
    "Markdown(', '.join(sorted([attr[:-1] for attr in set(token_attrs) & set([attr + '_' for attr in token_attrs])])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfa7be5-579e-4010-aecc-82fc811cfb15",
   "metadata": {},
   "source": [
    "spaCy の `doc` を Pandas DataFrame に読み込むとアクセスが簡単なので、変換する。以下の例ではストップワードを除外している点に注意。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7977263-fb1f-4449-872d-709955b20a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>explain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>国境</td>\n",
       "      <td>国境</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>長い</td>\n",
       "      <td>長い</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>トンネル</td>\n",
       "      <td>トンネル</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>抜ける</td>\n",
       "      <td>抜ける</td>\n",
       "      <td>VERB</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>雪国</td>\n",
       "      <td>雪国</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>。</td>\n",
       "      <td>。</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punctuation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text lemma    POS      explain\n",
       "0    国境    国境   NOUN         noun\n",
       "1    長い    長い    ADJ    adjective\n",
       "2  トンネル  トンネル   NOUN         noun\n",
       "3   抜ける   抜ける   VERB         verb\n",
       "4    雪国    雪国   NOUN         noun\n",
       "5     。     。  PUNCT  punctuation"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([[t.text, t.lemma_, t.pos_, spacy.explain(t.pos_)] for t in doc if not t.is_stop],\n",
    "                  columns=[\"text\", \"lemma\", \"POS\", \"explain\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e646053a-62bd-4de3-a8b3-9c82b057b792",
   "metadata": {},
   "source": [
    "# 30. 形態素解析結果の読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8744208d-ee6a-47b1-b0cd-22c2257ef1c7",
   "metadata": {},
   "source": [
    "# 31. 動詞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fc94a9-ace2-4976-9524-d31a024fe9ed",
   "metadata": {},
   "source": [
    "# 32. 動詞の基本形"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d08d96-6246-4679-ac71-851364561373",
   "metadata": {},
   "source": [
    "# 33. 「AのB」"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf694f-e294-4aee-b938-3868af3f0649",
   "metadata": {},
   "source": [
    "# 34. 名詞の連接"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a9624e-1f59-42ea-9b37-c2dfd76e53d7",
   "metadata": {},
   "source": [
    "# 35. 単語の出現頻度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3396bf0c-5058-4306-8320-0bb7342182cc",
   "metadata": {},
   "source": [
    "# 36. 頻度上位10語"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc63f2f4-1c3b-4aef-b678-4de35026fa33",
   "metadata": {},
   "source": [
    "# 37. 「猫」と共起頻度の高い上位10語"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa0d66a-df42-4c31-863e-c4a1f7706dbe",
   "metadata": {},
   "source": [
    "# 38. ヒストグラム"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94671064-13d6-4640-9b59-3ebf16634c4a",
   "metadata": {},
   "source": [
    "# 39. Zipfの法則"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68afc7f-11ea-4cde-ab57-dd60cf34ff97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
